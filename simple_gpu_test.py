# simple_gpu_test.py
"""
ğŸ§  Teste Simples da ExpansÃ£o GPU AEONCOSMA
Demonstra capacidades GPU simuladas sem dependÃªncias externas
Desenvolvido por Luiz Cruz - 2025
"""

import time
import sys
import os
import json

# Adiciona path para importaÃ§Ãµes
sys.path.append(os.path.join(os.path.dirname(__file__), 'aeoncosma'))

def test_node_brain_basic():
    """Teste bÃ¡sico do NodeBrain sem dependÃªncias"""
    print("ğŸ§  Teste NodeBrain Simulado")
    print("-" * 30)
    
    try:
        from aeoncosma.gpu.node_brain import NodeBrain
        
        # Cria brain
        brain = NodeBrain()
        
        # Testa mÃºltiplas decisÃµes
        test_cases = [
            [0.8, 0.7, 0.9, 0.6, 0.5, 0.4, 0.3],  # Peer muito bom
            [0.2, 0.1, 0.3, 0.2, 0.8, 0.9, 0.1],  # Peer mÃ©dio
            [0.1, 0.2, 0.1, 0.1, 0.0, 0.1, 0.0],  # Peer ruim
        ]
        
        results = []
        for i, features in enumerate(test_cases):
            decision = brain.make_decision(features)
            results.append(decision)
            
            print(f"  Teste {i+1}: {'âœ…' if decision['decision'] else 'âŒ'} "
                  f"ConfianÃ§a: {decision['confidence']:.3f} - {decision['reasoning'][:30]}...")
        
        # EstatÃ­sticas
        stats = brain.get_brain_stats()
        print(f"ğŸ“Š Total decisÃµes: {stats['total_decisions']}")
        print(f"ğŸ“ˆ Taxa de aceitaÃ§Ã£o: {stats['acceptance_rate']:.1%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

def test_gpu_manager_basic():
    """Teste bÃ¡sico do GPU Manager"""
    print("\nğŸ› ï¸ Teste GPU Manager Simulado")
    print("-" * 30)
    
    try:
        from aeoncosma.gpu.gpu_utils import GPUManager, PerformanceProfiler
        
        # Cria manager
        manager = GPUManager(0)
        profiler = PerformanceProfiler()
        
        # Simula operaÃ§Ã£o
        def dummy_work():
            total = 0
            for i in range(10000):
                total += i * 0.001
            return total
        
        # Perfila operaÃ§Ã£o
        result = profiler.profile_operation("simulation_work", dummy_work)
        
        print(f"  âš¡ OperaÃ§Ã£o: {result['profile']['operation']}")
        print(f"  â±ï¸ Tempo: {result['profile']['execution_time']:.4f}s")
        print(f"  âœ… Sucesso: {result['profile']['success']}")
        
        # Info do manager
        info = manager.get_memory_info()
        print(f"ğŸ“Š GPU Mode: {'Real GPU' if info['total'] > 0 else 'CPU Simulation'}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

def test_network_simulation():
    """Teste de simulaÃ§Ã£o de rede"""
    print("\nğŸŒ Teste SimulaÃ§Ã£o de Rede")
    print("-" * 30)
    
    try:
        from aeoncosma.gpu.node_brain import NodeBrain
        
        # Simula rede com 5 nÃ³s
        nodes = []
        for i in range(5):
            brain = NodeBrain()
            nodes.append({
                "id": f"node_{i:03d}",
                "brain": brain,
                "peers": [],
                "decisions": 0
            })
        
        # Simula descoberta de peers
        print("ğŸ” Simulando descoberta de peers...")
        
        total_connections = 0
        total_decisions = 0
        
        for i, node in enumerate(nodes):
            for j, peer in enumerate(nodes):
                if i != j:  # NÃ£o conecta consigo mesmo
                    # Features fictÃ­cias do peer
                    peer_features = [
                        hash(peer["id"]) % 1000 / 1000.0,  # ID hash
                        0.5 + (j * 0.1),  # VariaÃ§Ã£o baseada no Ã­ndice
                        0.8,  # Timestamp recency
                        0.6,  # Reputation
                        len(node["peers"]) / 10.0,  # Network density
                        0.7,  # Uptime
                        0.5   # Random
                    ]
                    
                    # NÃ³ decide sobre o peer
                    decision = node["brain"].make_decision(peer_features)
                    total_decisions += 1
                    
                    if decision["decision"]:
                        node["peers"].append(peer["id"])
                        total_connections += 1
                        print(f"  âœ… {node['id']} aceita {peer['id']} (conf: {decision['confidence']:.2f})")
                    else:
                        print(f"  âŒ {node['id']} rejeita {peer['id']} (conf: {decision['confidence']:.2f})")
        
        # EstatÃ­sticas da rede
        print(f"\nğŸ“Š EstatÃ­sticas da Rede:")
        print(f"  ğŸ¯ NÃ³s: {len(nodes)}")
        print(f"  ğŸ”— ConexÃµes: {total_connections}")
        print(f"  ğŸ§  DecisÃµes: {total_decisions}")
        print(f"  ğŸ“ˆ Taxa de aceitaÃ§Ã£o: {total_connections/total_decisions:.1%}")
        
        # Info detalhada de cada nÃ³
        for node in nodes:
            stats = node["brain"].get_brain_stats()
            print(f"  ğŸ“¡ {node['id']}: {len(node['peers'])} peers, "
                  f"{stats['total_decisions']} decisÃµes, "
                  f"{stats['acceptance_rate']:.1%} aceitaÃ§Ã£o")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

def test_art_generation_simulation():
    """Teste de geraÃ§Ã£o de arte simulada"""
    print("\nğŸ¨ Teste GeraÃ§Ã£o de Arte Simulada")
    print("-" * 30)
    
    try:
        from aeoncosma.gpu.stable_diffusion_visualizer import NetworkArtGenerator
        
        # Cria gerador (vai usar simulaÃ§Ã£o)
        generator = NetworkArtGenerator()
        
        # Estado fictÃ­cio da rede
        network_state = {
            "total_nodes": 1000,
            "active_nodes": 750,
            "consensus_strength": 0.85,
            "ai_confidence": 0.73,
            "connections_density": 0.6,
            "timestamp": "2025-07-27T12:00:00"
        }
        
        # Gera prompt criativo
        prompt_data = generator.network_state_to_prompt(network_state)
        
        print(f"ğŸ¯ Prompt gerado:")
        print(f"  {prompt_data['prompt'][:100]}...")
        
        print(f"\nğŸ“Š MÃ©tricas da rede:")
        for key, value in prompt_data['network_metrics'].items():
            print(f"  {key}: {value}")
        
        # Simula geraÃ§Ã£o de arte
        print(f"\nğŸ¨ Simulando geraÃ§Ã£o de arte...")
        result = generator.generate_network_art(network_state)
        
        if result["success"]:
            print(f"  âœ… Arte gerada: {result['metadata']['filename']}")
            print(f"  ğŸ• SimulaÃ§Ã£o: {result['metadata'].get('simulation', False)}")
        else:
            print(f"  âŒ Falha: {result['error']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

def comprehensive_gpu_demo():
    """DemonstraÃ§Ã£o completa das capacidades GPU"""
    print("ğŸŒŸ AEONCOSMA GPU EXPANSION - DEMONSTRAÃ‡ÃƒO COMPLETA")
    print("=" * 60)
    
    # Executar todos os testes
    tests = [
        ("NodeBrain IA Neural", test_node_brain_basic),
        ("GPU Manager", test_gpu_manager_basic),
        ("SimulaÃ§Ã£o de Rede", test_network_simulation),
        ("GeraÃ§Ã£o de Arte", test_art_generation_simulation)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª {test_name}")
        print("=" * 60)
        
        start_time = time.time()
        success = test_func()
        end_time = time.time()
        
        results.append({
            "test": test_name,
            "success": success,
            "duration": end_time - start_time
        })
        
        print(f"â±ï¸ DuraÃ§Ã£o: {end_time - start_time:.2f}s")
        print(f"{'âœ… SUCESSO' if success else 'âŒ FALHA'}")
    
    # Resumo final
    print(f"\nğŸ† RESUMO FINAL")
    print("=" * 60)
    
    success_count = sum(1 for r in results if r["success"])
    total_time = sum(r["duration"] for r in results)
    
    print(f"âœ… Testes bem-sucedidos: {success_count}/{len(results)}")
    print(f"â±ï¸ Tempo total: {total_time:.2f}s")
    print(f"ğŸ“Š Taxa de sucesso: {success_count/len(results):.1%}")
    
    for result in results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"  {status} {result['test']}: {result['duration']:.2f}s")
    
    print(f"\nğŸŒŸ AEONCOSMA estÃ¡ pronto para:")
    print(f"  ğŸ® Processamento GPU massivo (simulado)")
    print(f"  ğŸ§  IA embarcada em cada nÃ³")
    print(f"  ğŸŒ SimulaÃ§Ã£o de 100k+ nÃ³s")
    print(f"  ğŸ¨ GeraÃ§Ã£o de arte da rede")
    print(f"  ğŸ“Š Monitoramento em tempo real")
    
    return success_count == len(results)

def main():
    """ExecuÃ§Ã£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='AEONCOSMA Simple GPU Test')
    parser.add_argument('--brain', action='store_true', help='Testa apenas NodeBrain')
    parser.add_argument('--gpu', action='store_true', help='Testa apenas GPU Manager')
    parser.add_argument('--network', action='store_true', help='Testa apenas simulaÃ§Ã£o de rede')
    parser.add_argument('--art', action='store_true', help='Testa apenas geraÃ§Ã£o de arte')
    parser.add_argument('--demo', action='store_true', help='DemonstraÃ§Ã£o completa')
    
    args = parser.parse_args()
    
    if args.brain:
        test_node_brain_basic()
    elif args.gpu:
        test_gpu_manager_basic()
    elif args.network:
        test_network_simulation()
    elif args.art:
        test_art_generation_simulation()
    elif args.demo or not any([args.brain, args.gpu, args.network, args.art]):
        comprehensive_gpu_demo()

if __name__ == "__main__":
    main()
